<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WS1J1K9PZM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WS1J1K9PZM');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Zhoujun Cheng | Homepage</title>
  
  <meta name="author" content="Zhoujun Cheng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê≥</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhoujun Cheng ÊâøÊ¥≤È™è</name>
              </p>
              <p>Glad to meet you here! I am Zhoujun <small style="color:blueviolet">(pronounced similar to Jorge)</small>, a final-year Master student at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>  advised by Prof. <a href="https://www.cs.sjtu.edu.cn/~chengfan/index.html">Fan Cheng</a>.
                Before that, I received the B.S. degree in computer science (IEEE class) at SJTU. Currently, I work as a research assistant in HKUNLP group advised by Prof. <a href="https://taoyds.github.io/">Tao Yu</a>. I also worked closely with Senior Researcher <a href="https://www.microsoft.com/en-us/research/people/hadong/">Haoyu Dong</a> in Microsoft Research Asia.
              </p>

              <p>
                  My research interest lies in NLP, especially language agents, neuro-symbolic reasoning/code generation, and structured knowledge grounding.

              </p>
                <p>
                    I am looking for a Ph.D. position starting from 2024 Fall. Please feel free to contact me if you are interested in my research.
                </p>
              <p style="text-align:left">
                    <a href="mailto:blankcheng@sjtu.edu.cn"><img src="images/mail.svg" alt="Email" style="vertical-align:middle;" width="24" height="24"></a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=t41vrrQAAAAJ&hl=en"><img src="images/google-scholar.svg" alt="Google Scholar" style="vertical-align:middle;" width="24" height="24"></a> &nbsp/&nbsp
                    <a href="https://www.semanticscholar.org/author/Zhoujun-Cheng/1471878967"><img src="images/semantic-scholar.svg" alt="Semantic Scholar" style="vertical-align:middle;" width="26" height="26"></a> &nbsp/&nbsp
                    <a href="https://twitter.com/ChengZhoujun"><img src="images/twitter.svg" alt="Twitter" style="vertical-align:middle;" width="30" height="30"></a> &nbsp/&nbsp
                    <a href="https://github.com/BlankCheng"><img src="images/github-alt.svg" alt="github" style="vertical-align:middle;" width="24" height="24"></a> &nbsp/&nbsp
                    <a href="./data/resume.pdf"><img src="images/resume.png" alt="cv" style="vertical-align:middle;" width="24" height="24"></a>

              </p>
            </td>
            <td style="padding:2.5%;width:45%;max-width:45%">
              <a href="images/nz2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/nz2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



<!--************************************* Projects *************************************************-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/openagents.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/xlang-ai/OpenAgents">
                    <papertitle>OpenAgents <span style="color: red;">(3K github stars, 6K demo users)</span></papertitle>
              </a>
              <br>
              <p>OpenAgents is a platform for LLM-powered Agents, serving as user-centric intelligent agents and are easily deployed locally. We developed agents targeting three real-world scenarios, including:</p>
                <li>
                    <strong>Data Agent</strong>: code interpreter augmented with data tools
                </li>
                <li>
                    <strong>Plugins Agent</strong>: 200+ plugins for daily life
                </li>
                <li>
                    <strong>Web Agent</strong>: autonomous web browsing
                </li>
              <br>
              <a href="https://chat.xlang.ai">demo</a> |
              <a href="https://github.com/xlang-ai/OpenAgents">code</a> |
              <a href="https://docs.xlang.ai">docs</a> |
              <a href="https://twitter.com/ChengZhoujun/status/1714343204148113860">twitter</a>
            </td>
          </tr>

        </tbody></table>


<!--************************************* Publications *************************************************-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2310.10634">
                <papertitle>OpenAgents: An Open Platform for Language Agents in the Wild</papertitle>
              </a>
              <br>
                Tianbao Xie*, Fan Zhou*, <strong>Zhoujun Cheng*</strong>, Peng Shi*, Luoxuan Weng*, Yitao Liu*, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu, Hongjin Su, Dongchan Shin, Caiming Xiong, Tao Yu
              <br>
<!--              <strong><em>ICLR</em> 2023<font style="color:red;"> (Spotlight)</font></strong>-->
              <strong><em>Preprint 10.2023</em></strong>
              <br>
              <a href="https://arxiv.org/pdf/2310.10634.pdf">pdf</a> |
              <a href="https://github.com/xlang-ai/OpenAgents">code</a> |
              <a href="https://chat.xlang.ai">demo</a> |
              <a href="https://docs.xlang.ai">docs</a>
              <p>An open platform for using, hosting, and building language agents.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2310.06830">
                <papertitle>Lemur: Harmonizing Natural Language and Code for Language Agents</papertitle>
              </a>
              <br>
                Yiheng Xu*, Hongjin Su*, Chen Xing*, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, <strong>Zhoujun Cheng</strong>, Siheng Zhao, Lingpeng Kong, Bailin Wang, Caiming Xiong, Tao Yu
              <br>
<!--              <strong><em>ICLR</em> 2023<font style="color:red;"> (Spotlight)</font></strong>-->
              <strong><em>ICLR</em> 2024 <span style="color: red;">(Spotlight)</span></strong>
              <br>
              <a href="https://arxiv.org/pdf/2310.06830.pdf">pdf</a> |
              <a href="https://github.com/OpenLemur/Lemur">code</a> |
              <a href="https://huggingface.co/OpenLemur/lemur-70b-v1">checkpoint</a>
              <p>A pretrained 70B agent model with balanced code-text corpora.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2210.02875">
                <papertitle>Binding Language Models in Symbolic Languages</papertitle>
              </a>
              <br>
                <strong>Zhoujun Cheng*</strong>, Tianbao Xie*, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, Tao Yu
              <br>
<!--              <strong><em>ICLR</em> 2023<font style="color:red;"> (Spotlight)</font></strong>-->
              <strong><em>ICLR</em> 2023 <span style="color: red;">(Spotlight)</span></strong>
              <br>
              <a href="https://arxiv.org/pdf/2210.02875.pdf">pdf</a> |
              <a href="https://github.com/HKUNLP/Binder">code</a> |
              <a href="https://huggingface.co/spaces/hkunlp/Binder">demo</a>
              <p>A training-free neural-symbolic framework mapping task inputs to programs of LLM calls + symbolic languages.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/binder.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2301.08721">
                <papertitle>Batch Prompting: Efficient Inference with Large Language Model APIs</papertitle>
              </a>
              <br>
                <strong>Zhoujun Cheng</strong>, Jungo Kasai, Tao Yu
              <br>
              <strong><em>EMNLP</em>  2023 Industry Track</strong>
              <br>
              <a href="https://arxiv.org/pdf/2301.08721.pdf">pdf</a> |
              <a href="https://github.com/HKUNLP/batch-prompting">code</a>
              <p>A simple prompting approach that enables the LLMs to run inference in batches to save budgets&time.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/tacube.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2205.12682">
                <papertitle>TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data</papertitle>
              </a>
              <br>
                Fan Zhou, Mengkang Hu, Haoyu Dong, <strong>Zhoujun Cheng</strong>, Shi Han, Dongmei Zhang
              <br>
              <strong><em>EMNLP</em>  2022 <span style="color: red;">(Oral)</span></strong>
              <br>
              <a href="https://arxiv.org/pdf/2205.12682.pdf">pdf</a> |
              <a href="https://github.com/koalazf99/tacube">code</a>
              <p>Precomputing aggregation/arithmetic results to assist table numerical reasoning.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/hitab.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2108.06712">
                <papertitle>HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation</papertitle>
              </a>
              <br>
                <strong>Zhoujun Cheng*</strong>, Haoyu Dong*, Zhiruo Wang*, Ran Jia, Jiaqi Guo, Yan Gao, Shi Han, Jian-Guang Lou, Dongmei Zhang
              <br>
              <strong><em>ACL</em>  2022</strong>
              <br>
              <a href="https://arxiv.org/pdf/2108.06712.pdf">pdf</a> |
              <a href="https://github.com/microsoft/HiTab">code</a> |
              <a href="https://github.com/microsoft/HiTab">dataset</a>
              <p>A hierarchical table dataset for question answering and natural language generation.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/fortap.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2109.07323">
                <papertitle>FORTAP: Using Formulae for Numerical-Reasoning-Aware Table Pretraining</papertitle>
              </a>
              <br>
                <strong>Zhoujun Cheng*</strong>, Haoyu Dong*, Ran Jia, Pengfei Wu, Shi Han, Fan Cheng, Dongmei Zhang
              <br>
              <strong><em>ACL</em>  2022</strong>
              <br>
              <a href="https://arxiv.org/pdf/2109.07323.pdf">pdf</a> |
              <a href="https://github.com/microsoft/TUTA_table_understanding">code</a>
              <p></p>
              <p>Adopting spreadsheet formulas to enhance numerical reasoning skills of table modeling.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/table_survey.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2201.09745">
                <papertitle>Table Pre-training: A Survey on Model Architectures, Pretraining Objectives, and Downstream Tasks</papertitle>
              </a>
              <br>
              Haoyu Dong, <strong>Zhoujun Cheng</strong>, Xinyi He, Mengyu Zhou, Anda Zhou, Fan Zhou, Ao Liu, Shi Han, Dongmei Zhang
              <br>
              <strong><em>IJCAI</em> 2022 Survey Track</strong>
              <br>
              <a href="https://arxiv.org/pdf/2201.09745.pdf">pdf</a>
              <p></p>
              <p>A survey on various tabular models, especially on the pretrained transformers. </p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/keypointnet.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2002.12687">
                <papertitle>KeypointNet: A Large-scale 3D Keypoint Dataset Aggregated from Numerous Human Annotations</papertitle>
              </a>
              <br>
              Yang You, Yujing Lou*, Chengkun Li*, <strong>Zhoujun Cheng</strong>, Liangwei Li, Lizhuang Ma, Cewu Lu, Weiming Wang
              <br>
              <strong><em>CVPR</em>  2020</strong>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/You_KeypointNet_A_Large-Scale_3D_Keypoint_Dataset_Aggregated_From_Numerous_Human_CVPR_2020_paper.pdf">pdf</a> |
              <a href="https://github.com/qq456cvb/KeypointNet">code</a>
              <p></p>
              <p>A large-scale and diverse 3D keypoint dataset.</p>
            </td>
          </tr>


          <tr>
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div>-->
<!--                <img src='images/human_correspondence.png' width="160">-->
<!--              </div>-->
<!--            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1912.12577">
                <papertitle>Human Correspondence Consensus for 3D Object Semantic Understanding</papertitle>
              </a>
              <br>
              Yujing Lou*, Yang You*, Chengkun Li*, <strong>Zhoujun Cheng</strong>, Liangwei Li, Lizhuang Ma, Weiming Wang, Cewu Lu
              <br>
              <strong><em>ECCV</em>  2020</strong>

              <br>
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670494.pdf">pdf</a> |
              <a href="https://github.com/yokinglou/CorresPondenceNet">code</a>
              <p></p>
              <p>Learning dense semantic correspondences on 3D objects.</p>
            </td>
          </tr>
        </tbody></table>


<!--************************************* Awards *************************************************-->
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards&Services</heading>
            </td>
          </tr>
        </tbody></table>

        <div style="margin-left: 5%">
              <li>Reviewer of ACL Rolling Review 2022/2023, EACL 2024, NAACL 2024 (incoming), NAACL SUKI Workshop 2022, NeurIPS TRL Workshop 2022/2023, ICLR DL4C Workshop 2022</li>
              <li>National Scholarship (top 2%), 2018</li>
              <li>Shanghai Outstanding Graduates, 2021</li>
              <li>MSRA Stars of Tomorrow (Award of Excellent Intern), 2021</li>
              <li>SJTU Zhiyuan Honors Scholarship (top 5%), 2018-2020</li>
        </div>



<!--************************************* Beyond Academics *************************************************-->
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Beyond Academics</heading>
            </td>
          </tr>
        </tbody></table>

        <div style="margin-left: 5%">
          <p>
            I am a fan of NBA and enjoy playing basketball. I would like to highly recommend a Sina Weibo blogger <a href="https://weibo.com/u/1665176985">@ÊóãÁå´</a>, who provides professional and insightful analysis on NBA in China.
            <br>
            I also have fun with Dota2 (usually watch games rather than playing it myself, a.k.a. ‰∫ëÁé©ÂÆ∂)
          </p>
        </div>

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <td style="padding:10px;width:75%;vertical-align:middle">-->
        <div style="margin-left: 5%">

        </div>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Last update on November 2023
                <br>
                <br>
                Design and source code from <a href="https://github.com/jonbarron/website">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
